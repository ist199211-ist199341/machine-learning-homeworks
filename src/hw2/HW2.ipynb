{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework I\n",
    "\n",
    "Diogo Correia (ist199211) & Tom√°s Esteves (ist199341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [13v]\n",
    "\n",
    "**Four positive observations,{$ A \\choose 0 $, $ B \\choose 1 $, $ A \\choose 1 $, $ A \\choose 0 $} , , and four negative observations, {$ B \\choose 0 $, $ B \\choose 0 $, $ A \\choose 1 $, $ B \\choose 1 $} , were collected. Consider the problem of classifying observations as positive or negative.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [4v] Compute the recall of a distance-weighted ùëòNN with ùëò = 5 and distance ùëë(ùê±1 , ùê±2) = ùêªùëéùëöùëöùëñùëõùëî(ùê±1 , ùê±2) + $\\frac{1}{2}$ using leave-one-out evaluation schema (i.e., when classifying one observation, use all remaining ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/hw2data.csv\")\n",
    "\n",
    "df = df.drop(\"y3\", axis=1)\n",
    "df = df.drop(df.index[4])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_IF_EQUAL = 1 / 2\n",
    "DISTANCE_IF_1_DIFFERENT = 3 / 2\n",
    "DISTANCE_IF_2_DIFFERENT = 5 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td colspan=\"2\" rowspan=\"2\" style=\"border-top: none; border-left: none;\"></td>\n",
    "    <th colspan=\"2\">True</th>\n",
    "    <td rowspan=\"2\" style=\"border-top: none; border-right: none;\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Positive</th>\n",
    "    <th>Negative</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Predicted</th>\n",
    "    <th>Positive</th>\n",
    "    <td>2</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Negative</th>\n",
    "    <td>2</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" style=\"border-left: none; border-bottom: none;\"></th>\n",
    "    <td>4</td>\n",
    "    <td>?</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_POSITIVE = 2\n",
    "FALSE_NEGATIVE = 2\n",
    "\n",
    "recall = TRUE_POSITIVE / (TRUE_POSITIVE + FALSE_NEGATIVE)\n",
    "\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An additional negitive observation was acquired, ( $ùêµ \\choose 0$), and a third variable ùë¶3 was independently monitored, yielding estimates ùë¶3|ùëÉ = {1.2, 0.8, 0.5, 0.9,0.8} , and ùë¶3|ùëÅ = {1, 0.9, 1.2, 0.8}.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [4v] Considering the nine training observations, learn a Bayesian classifier assuming:\n",
    "i) ùë¶1 and ùë¶2 are dependent\\\n",
    "ii) {ùë¶1, ùë¶2} , and {ùë¶3} , variable sets are independent and equally important\\\n",
    "ii) ùë¶3 is normally distributed. \n",
    "\n",
    "Show all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/hw2data.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\n",
    "P( class \\ | \\ y_1 = v_1, \\ y_2 = v_2) = \\frac{P(y_1 = v_1, \\ y_2 = v_2 | \\ class) \\times P(class)}{P(y_1 = v_1, \\ y_2 = v_2)} \n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(pos) = \\frac{5}{9}, \\ \\ \\\n",
    "P(neg) = \\frac{4}{9}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0) = \\frac{2}{9} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1) = \\frac{2}{9} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0) = \\frac{3}{9} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1) = \\frac{2}{9}   \\ \\ \\\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0 \\ | Pos) = \\frac{2}{5} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1 \\ | Pos) = \\frac{1}{5} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0 \\ | Pos) = \\frac{1}{5} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1 \\ | Pos) = \\frac{1}{5}   \\ \\ \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0 \\ | Neg) = \\frac{0}{4} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1 \\ | Neg) = \\frac{1}{4} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0 \\ | Neg) = \\frac{2}{4} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1 \\ | Neg) = \\frac{1}{4}   \\ \\ \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(x | \\mu, \\sigma^2) = \\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{e ^{- \\frac{(x- \\mu)^2}{2 \\sigma^2}}}{\\sqrt{2 \\pi} \\times \\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y3) \\          \\mu = 0.9, \\ \\sigma = 0.21794494717703364\\\\\n",
    "P(y3 | \\ Pos) \\  \\mu = 0.8, \\ \\sigma = 0.25099800796022265\\\\\n",
    "P(y3 | \\ Neg) \\  \\mu = 1.0, \\ \\sigma = 0.17078251276599327\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos = 5 / 9\n",
    "prob_neg = 4 / 9\n",
    "\n",
    "prob_A_0 = 2 / 9\n",
    "prob_A_1 = 2 / 9\n",
    "prob_B_0 = 3 / 9\n",
    "prob_B_1 = 2 / 9\n",
    "\n",
    "prob_A_0_pos = 2 / 5\n",
    "prob_A_1_pos = 1 / 5\n",
    "prob_B_0_pos = 1 / 5\n",
    "prob_B_1_pos = 1 / 5\n",
    "\n",
    "prob_A_0_neg = 0\n",
    "prob_A_1_neg = 1 / 4\n",
    "prob_B_0_neg = 2 / 4\n",
    "prob_B_1_neg = 1 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy\n",
    "\n",
    "y3_values = df[\"y3\"]\n",
    "\n",
    "mean_all = numpy.mean(y3_values)\n",
    "sd_all = numpy.std(y3_values, ddof=1)\n",
    "\n",
    "print(\"all\", mean_all, sd_all)\n",
    "\n",
    "y3_values_pos = y3_values[:5]\n",
    "\n",
    "mean_pos = numpy.mean(y3_values_pos)\n",
    "sd_pos = numpy.std(y3_values_pos, ddof=1)\n",
    "\n",
    "print(\"positive\", mean_pos, sd_pos)\n",
    "\n",
    "y3_values_neg = y3_values[5:]\n",
    "\n",
    "mean_neg = numpy.mean(y3_values_neg)\n",
    "sd_neg = numpy.std(y3_values_neg, ddof=1)\n",
    "\n",
    "print(\"negative\", mean_neg, sd_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_12 = scipy.stats.norm(mean_all, sd_all).pdf(1.2)\n",
    "prob_08 = scipy.stats.norm(mean_all, sd_all).pdf(0.8)\n",
    "prob_05 = scipy.stats.norm(mean_all, sd_all).pdf(0.5)\n",
    "prob_09 = scipy.stats.norm(mean_all, sd_all).pdf(0.9)\n",
    "prob_1 = scipy.stats.norm(mean_all, sd_all).pdf(1)\n",
    "\n",
    "prob_12_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(1.2)\n",
    "prob_08_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(0.8)\n",
    "prob_05_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(0.5)\n",
    "prob_09_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(0.9)\n",
    "prob_1_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos_A_0_y3 = prob_pos * prob_A_0_pos / (prob_A_0)\n",
    "prob_pos_A_1_y3 = prob_pos * prob_A_1_pos / (prob_A_1)\n",
    "prob_pos_B_0_y3 = prob_pos * prob_B_0_pos / (prob_B_0)\n",
    "prob_pos_B_1_y3 = prob_pos * prob_B_1_pos / (prob_B_1)\n",
    "\n",
    "prob_neg_A_0_y3 = prob_neg * prob_A_0_neg / (prob_A_0)\n",
    "prob_neg_A_1_y3 = prob_neg * prob_A_1_neg / (prob_A_1)\n",
    "prob_neg_B_0_y3 = prob_neg * prob_B_0_neg / (prob_B_0)\n",
    "prob_neg_B_1_y3 = prob_neg * prob_B_1_neg / (prob_B_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considering three testing observations, {((A, 1, 0.8), Positive), ((B, 1, 1), Positive), ((B, 0, 0.9), Negative)}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [3v] Under a MAP assumption, compute ùëÉ(Positive|ùê±) of each testing observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos |x) = \\frac{p(x|pos) \\times p(pos)}{p(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = A , y_2 = 1 , y_3 = 0.8) =\n",
    "\\frac{p ( y_1 = A , y_2 = 1 | pos) \\times p(y_3 = 0.8 | pos) \\times p(pos)}{p(y_1 = A , y_2 = 1) \\times p(y_3 = 0.8)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = A , y_2 = 1 , y_3 = 0.8) =\n",
    "\\frac{\\frac{1}{5} \\times 1.569368533344791 \\times \\frac{5}{9}}{\\frac{3}{9} \\times 1.6475858460095913}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = A , y_2 = 1 , y_3 = 0.8) = 0.4762630539542932\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos) / P(X)\n",
    "\n",
    "\n",
    "p_x = prob_pos * prob_A_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(\n",
    "    0.8\n",
    ") + prob_neg * prob_A_1_neg * scipy.stats.norm(mean_neg, sd_neg).pdf(0.8)\n",
    "\n",
    "\n",
    "print(prob_pos * (prob_A_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(0.8)) / p_x)\n",
    "\n",
    "p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 1 , y_3 = 1) =\n",
    "\\frac{p ( y_1 = B , y_2 = 1 | pos) \\times p(y_3 = 1 | pos) \\times p(pos)}{p(y_1 = B , y_2 = 1) \\times p(y_3 = 1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 1 , y_3 = 1) =\n",
    "\\frac{\\frac{1}{5} \\times 1.297185788557846 \\times \\frac{5}{9}}{\\frac{2}{9} \\times 1.6475858460095925}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 1 , y_3 = 1) = 0.39366257961598616\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos)\n",
    "\n",
    "p_x = prob_pos * prob_B_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(\n",
    "    1\n",
    ") + prob_neg * prob_B_1_neg * scipy.stats.norm(mean_neg, sd_neg).pdf(1)\n",
    "\n",
    "\n",
    "print(prob_pos * (prob_B_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(1)) / p_x)\n",
    "\n",
    "p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 0 , y_3 = 0.9) =\n",
    "\\frac{p ( y_1 = B , y_2 = 0 | pos) \\times p(y_3 = 0.9 | pos) \\times p(pos)}{p(y_1 = B , y_2 = 0) \\times p(y_3 = 0.9)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 0 , y_3 = 0.9) =\n",
    "\\frac{\\frac{1}{5} \\times 1.5446545830601983 \\times \\frac{5}{9}}{\\frac{3}{9} \\times 1.8304727206058027}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 0 , y_3 = 0.9) = 0.28128518673015945\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos)\n",
    "\n",
    "\n",
    "p_x = prob_pos * prob_B_0_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(\n",
    "    0.9\n",
    ") + prob_neg * prob_B_0_neg * scipy.stats.norm(mean_neg, sd_neg).pdf(0.9)\n",
    "\n",
    "\n",
    "print(prob_pos * (prob_B_0_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(0.9)) / p_x)\n",
    "p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [2v] Given a binary class variable, the default decision threshold of ùúÉ = 0.5,\n",
    "f(x|ùúÉ) = Pos, if P(Positive|x) > 0\\\n",
    "Else negative\n",
    "\n",
    "can be adjusted. Which decision threshold ‚Äì 0.3, 0.5 or 0.7 ‚Äì optimizes testing accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming [7v]\n",
    "\n",
    "**Considering the `pd_speech.arff` dataset available at the homework tab:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) [3v]\n",
    "\n",
    "Using sklearn, considering a 10-fold stratified cross validation (random=0), plot the cumulative\n",
    "testing confusion matrices of ùëòNN (uniform weights, ùëò = 5, Euclidean distance) and Na√Øve Bayes\n",
    "(Gaussian assumption). Use all remaining classifier parameters as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the ARFF file\n",
    "data = loadarff(\"../data/pd_speech.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "df[\"class\"] = df[\"class\"].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from the outcome (class)\n",
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_knn = KNeighborsClassifier(\n",
    "    weights=\"uniform\", n_neighbors=5, metric=\"euclidean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_naive_bayes = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_prob = []\n",
    "naive_bayes_prob = []\n",
    "\n",
    "knn_acc = []\n",
    "naive_bayes_acc = []\n",
    "\n",
    "y_test_values = []\n",
    "\n",
    "for train_k, test_k in folds.split(X, y):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_k], X.iloc[test_k]\n",
    "    y_train, y_test = y.iloc[train_k], y.iloc[test_k]\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    predictor_knn.fit(X_train, y_train)\n",
    "    predictor_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "    knn_test_pred = predictor_knn.predict(X_test)\n",
    "    naive_bayes_test_pred = predictor_naive_bayes.predict(X_test)\n",
    "\n",
    "    knn_prob += knn_test_pred.tolist()\n",
    "    naive_bayes_prob += naive_bayes_test_pred.tolist()\n",
    "    y_test_values += y_test.tolist()\n",
    "\n",
    "    # Get the accuracy of each test\n",
    "    knn_acc.append(accuracy_score(y_test, knn_test_pred))\n",
    "    naive_bayes_acc.append(accuracy_score(y_test, naive_bayes_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cm = np.array(confusion_matrix(y_test_values, knn_prob, labels=([\"0\", \"1\"])))\n",
    "\n",
    "knn_confusion = pd.DataFrame(\n",
    "    knn_cm,\n",
    "    index=[\"Healthy\", \"Parkinson\"],\n",
    "    columns=[\"Predicted Healthy\", \"Predicted Parkinson\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(knn_confusion, annot=True, fmt=\"g\", cmap=\"Greens\", ax=ax)\n",
    "ax.set_title(\"kNN Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_naive_bayes = np.array(\n",
    "    confusion_matrix(y_test_values, naive_bayes_prob, labels=([\"0\", \"1\"]))\n",
    ")\n",
    "\n",
    "confusion_naive_bayes = pd.DataFrame(\n",
    "    cm_naive_bayes,\n",
    "    index=[\"Healthy\", \"Parkinson\"],\n",
    "    columns=[\"Predicted Healthy\", \"Predicted Parkinson\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(confusion_naive_bayes, annot=True, fmt=\"g\", cmap=\"Greens\", ax=ax)\n",
    "ax.set_title(\"Naive Bayes Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) [2v] Using scipy, test the hypothesis ‚ÄúùëòNN is statistically superior to Na√Øve Bayes regarding accuracy‚Äù, asserting whether is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor 1 is better than 2?\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"less\")\n",
    "print(\"knn > naive_bayes? pval=\", res.pvalue)\n",
    "\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"greater\")\n",
    "print(\"knn < naive_bayes? pval=\", res.pvalue)\n",
    "\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"two-sided\")\n",
    "print(\"knn == naive_bayes? pval=\", res.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion*: By the p-value gathered (pval = 0.0.9986831821715092) we cannot reject the hypothesis \"kNN is statistically superior to Na√Øve Bayes regarding accuracy\".\n",
    "\n",
    "VERIFICA Q ESTA CENA ESTA BEM PFV\n",
    "\n",
    "\"Examples for use are scores of the same set of student in different exams, or repeated sampling from the same units. The test measures whether the average score differs significantly across samples (e.g. exams). If we observe a large p-value, for example greater than 0.05 or 0.1 then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages. Small p-values are associated with large t-statistics.\" COPIADO DA NET retirar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) [2v] Enumerate three possible reasons that could underlie the observed differences in predictive accuracy between ùëòNN and Na√Øve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate five possible reasons that could underlie the observed differences in predictive accuracy between ùëòNN and Na√Øve Bayes.\n",
    "\n",
    "# 1. The data is not normally distributed\n",
    "# 2. The data is not independent\n",
    "# 3. The data is not homoscedastic\n",
    "# 4. The data is not balanced\n",
    "# 5. The data is not linearly separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN DISAVANTAGES\n",
    "\n",
    "Accuracy depends on the quality of the data\n",
    "Sensitive to the scale of the data, IT SHOULD BE NORMALIZED and irrelevant features\n",
    "\n",
    "\n",
    "NAIVE BAYES DISAVANTAGES\n",
    "\n",
    "It assumes that all the features are independent. While it might sound great in theory, in real life, you‚Äôll hardly find a set of independent features. \n",
    "Highly doubt q todas sejam independentes\n",
    "f your test data set has a categorical variable of a category that wasn‚Äôt present in the training data set, the Naive Bayes model will assign it zero probability and won‚Äôt be able to make any predictions in this regard.\n",
    "\n",
    "A third problem arises for continuous features. It is common to use a binning procedure to make them discrete, but if you are not careful you can throw away a lot of information. Another possibility is to use Gaussian distributions for the likelihoods "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}

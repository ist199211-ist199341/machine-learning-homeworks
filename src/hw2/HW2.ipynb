{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework I\n",
    "\n",
    "Diogo Correia (ist199211) & TomÃ¡s Esteves (ist199341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [13v]\n",
    "\n",
    "**Four positive observations,{$ A \\choose 0 $, $ B \\choose 1 $, $ A \\choose 1 $, $ A \\choose 0 $} , , and four negative observations, {$ B \\choose 0 $, $ B \\choose 0 $, $ A \\choose 1 $, $ B \\choose 1 $} , were collected. Consider the problem of classifying observations as positive or negative.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [4v] Compute the recall of a distance-weighted ğ‘˜NN with ğ‘˜ = 5 and distance ğ‘‘(ğ±1 , ğ±2) = ğ»ğ‘ğ‘šğ‘šğ‘–ğ‘›ğ‘”(ğ±1 , ğ±2) + $\\frac{1}{2}$ using leave-one-out evaluation schema (i.e., when classifying one observation, use all remaining ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/hw2data.csv\")\n",
    "\n",
    "df = df.drop(\"y3\", axis=1)\n",
    "df = df.drop(df.index[4])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_IF_EQUAL = 1 / 2\n",
    "DISTANCE_IF_1_DIFFERENT = 3 / 2\n",
    "DISTANCE_IF_2_DIFFERENT = 5 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td colspan=\"2\" rowspan=\"2\" style=\"border-top: none; border-left: none;\"></td>\n",
    "    <th colspan=\"2\">True</th>\n",
    "    <td rowspan=\"2\" style=\"border-top: none; border-right: none;\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Positive</th>\n",
    "    <th>Negative</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Predicted</th>\n",
    "    <th>Positive</th>\n",
    "    <td>2</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Negative</th>\n",
    "    <td>2</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" style=\"border-left: none; border-bottom: none;\"></th>\n",
    "    <td>4</td>\n",
    "    <td>?</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_POSITIVE = 2\n",
    "FALSE_NEGATIVE = 2\n",
    "\n",
    "recall = TRUE_POSITIVE / (TRUE_POSITIVE + FALSE_NEGATIVE)\n",
    "\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An additional negitive observation was acquired, ( $ğµ \\choose 0$), and a third variable ğ‘¦3 was independently monitored, yielding estimates ğ‘¦3|ğ‘ƒ = {1.2, 0.8, 0.5, 0.9,0.8} , and ğ‘¦3|ğ‘ = {1, 0.9, 1.2, 0.8}.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [4v] Considering the nine training observations, learn a Bayesian classifier assuming:\n",
    "i) ğ‘¦1 and ğ‘¦2 are dependent\\\n",
    "ii) {ğ‘¦1, ğ‘¦2} , and {ğ‘¦3} , variable sets are independent and equally important\\\n",
    "ii) ğ‘¦3 is normally distributed. \n",
    "\n",
    "Show all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/hw2data.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\n",
    "P( class \\ | \\ y_1 = v_1, \\ y_2 = v_2) = \\frac{P(y_1 = v_1, \\ y_2 = v_2 | \\ class) \\times P(class)}{P(y_1 = v_1, \\ y_2 = v_2)} \n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(pos) = \\frac{5}{9}, \\ \\ \\\n",
    "P(neg) = \\frac{4}{9}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0) = \\frac{2}{9} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1) = \\frac{2}{9} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0) = \\frac{3}{9} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1) = \\frac{2}{9}   \\ \\ \\\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0 \\ | Pos) = \\frac{2}{5} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1 \\ | Pos) = \\frac{1}{5} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0 \\ | Pos) = \\frac{1}{5} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1 \\ | Pos) = \\frac{1}{5}   \\ \\ \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0 \\ | Neg) = \\frac{0}{4} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1 \\ | Neg) = \\frac{1}{4} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0 \\ | Neg) = \\frac{2}{4} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1 \\ | Neg) = \\frac{1}{4}   \\ \\ \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(x | \\mu, \\sigma^2) = \\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{e ^{- \\frac{(x- \\mu)^2}{2 \\sigma^2}}}{\\sqrt{2 \\pi} \\times \\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y3) \\          \\mu = 0.9, \\ \\sigma = 0.21794494717703364\\\\\n",
    "P(y3 | \\ Pos) \\  \\mu = 0.8, \\ \\sigma = 0.25099800796022265\\\\\n",
    "P(y3 | \\ Neg) \\  \\mu = 1.0, \\ \\sigma = 0.17078251276599327\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos = 5 / 9\n",
    "prob_neg = 4 / 9\n",
    "\n",
    "prob_A_0 = 2 / 9\n",
    "prob_A_1 = 2 / 9\n",
    "prob_B_0 = 3 / 9\n",
    "prob_B_1 = 2 / 9\n",
    "\n",
    "prob_A_0_pos = 2 / 5\n",
    "prob_A_1_pos = 1 / 5\n",
    "prob_B_0_pos = 1 / 5\n",
    "prob_B_1_pos = 1 / 5\n",
    "\n",
    "prob_A_0_neg = 0\n",
    "prob_A_1_neg = 1 / 4\n",
    "prob_B_0_neg = 2 / 4\n",
    "prob_B_1_neg = 1 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy\n",
    "\n",
    "y3_values = df[\"y3\"]\n",
    "\n",
    "mean_all = numpy.mean(y3_values)\n",
    "sd_all = numpy.std(y3_values, ddof=1)\n",
    "\n",
    "print(\"all\", mean_all, sd_all)\n",
    "\n",
    "y3_values_pos = y3_values[:5]\n",
    "\n",
    "mean_pos = numpy.mean(y3_values_pos)\n",
    "sd_pos = numpy.std(y3_values_pos, ddof=1)\n",
    "\n",
    "print(\"positive\", mean_pos, sd_pos)\n",
    "\n",
    "y3_values_neg = y3_values[5:]\n",
    "\n",
    "mean_neg = numpy.mean(y3_values_neg)\n",
    "sd_neg = numpy.std(y3_values_neg, ddof=1)\n",
    "\n",
    "print(\"negative\", mean_neg, sd_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_12 = scipy.stats.norm(mean_all, sd_all).pdf(1.2)\n",
    "prob_08 = scipy.stats.norm(mean_all, sd_all).pdf(0.8)\n",
    "prob_05 = scipy.stats.norm(mean_all, sd_all).pdf(0.5)\n",
    "prob_09 = scipy.stats.norm(mean_all, sd_all).pdf(0.9)\n",
    "prob_1 = scipy.stats.norm(mean_all, sd_all).pdf(1)\n",
    "\n",
    "prob_12_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(1.2)\n",
    "prob_08_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(0.8)\n",
    "prob_05_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(0.5)\n",
    "prob_09_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(0.9)\n",
    "prob_1_pos = scipy.stats.norm(mean_pos, sd_pos).pdf(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos_A_0_y3 = prob_pos * prob_A_0_pos / (prob_A_0)\n",
    "prob_pos_A_1_y3 = prob_pos * prob_A_1_pos / (prob_A_1)\n",
    "prob_pos_B_0_y3 = prob_pos * prob_B_0_pos / (prob_B_0)\n",
    "prob_pos_B_1_y3 = prob_pos * prob_B_1_pos / (prob_B_1)\n",
    "\n",
    "prob_neg_A_0_y3 = prob_neg * prob_A_0_neg / (prob_A_0)\n",
    "prob_neg_A_1_y3 = prob_neg * prob_A_1_neg / (prob_A_1)\n",
    "prob_neg_B_0_y3 = prob_neg * prob_B_0_neg / (prob_B_0)\n",
    "prob_neg_B_1_y3 = prob_neg * prob_B_1_neg / (prob_B_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considering three testing observations, {((A, 1, 0.8), Positive), ((B, 1, 1), Positive), ((B, 0, 0.9), Negative)}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [3v] Under a MAP assumption, compute ğ‘ƒ(Positive|ğ±) of each testing observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos |x) = \\frac{p(x|pos) \\times p(pos)}{p(x)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = A , y_2 = 1 , y_3 = 0.8) =\n",
    "\\frac{p ( y_1 = A , y_2 = 1 | pos) \\times p(y_3 = 0.8 | pos) \\times p(pos)}{p(y_1 = A , y_2 = 1) \\times p(y_3 = 0.8)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = A , y_2 = 1 , y_3 = 0.8) =\n",
    "\\frac{\\frac{1}{5} \\times 1.569368533344791 \\times \\frac{5}{9}}{\\frac{3}{9} \\times 1.6475858460095913}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = A , y_2 = 1 , y_3 = 0.8) = 0.4762630539542932\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos) / P(X)\n",
    "\n",
    "\n",
    "p_x = prob_pos * prob_A_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(\n",
    "    0.8\n",
    ") + prob_neg * prob_A_1_neg * scipy.stats.norm(mean_neg, sd_neg).pdf(0.8)\n",
    "\n",
    "\n",
    "print(prob_pos * (prob_A_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(0.8)) / p_x)\n",
    "\n",
    "p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 1 , y_3 = 1) =\n",
    "\\frac{p ( y_1 = B , y_2 = 1 | pos) \\times p(y_3 = 1 | pos) \\times p(pos)}{p(y_1 = B , y_2 = 1) \\times p(y_3 = 1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 1 , y_3 = 1) =\n",
    "\\frac{\\frac{1}{5} \\times 1.297185788557846 \\times \\frac{5}{9}}{\\frac{2}{9} \\times 1.6475858460095925}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 1 , y_3 = 1) = 0.39366257961598616\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos)\n",
    "\n",
    "p_x = prob_pos * prob_B_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(\n",
    "    1\n",
    ") + prob_neg * prob_B_1_neg * scipy.stats.norm(mean_neg, sd_neg).pdf(1)\n",
    "\n",
    "\n",
    "print(prob_pos * (prob_B_1_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(1)) / p_x)\n",
    "\n",
    "p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 0 , y_3 = 0.9) =\n",
    "\\frac{p ( y_1 = B , y_2 = 0 | pos) \\times p(y_3 = 0.9 | pos) \\times p(pos)}{p(y_1 = B , y_2 = 0) \\times p(y_3 = 0.9)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 0 , y_3 = 0.9) =\n",
    "\\frac{\\frac{1}{5} \\times 1.5446545830601983 \\times \\frac{5}{9}}{\\frac{3}{9} \\times 1.8304727206058027}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(pos| y_1 = B , y_2 = 0 , y_3 = 0.9) = 0.28128518673015945\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos)\n",
    "\n",
    "\n",
    "p_x = prob_pos * prob_B_0_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(\n",
    "    0.9\n",
    ") + prob_neg * prob_B_0_neg * scipy.stats.norm(mean_neg, sd_neg).pdf(0.9)\n",
    "\n",
    "\n",
    "print(prob_pos * (prob_B_0_pos * scipy.stats.norm(mean_pos, sd_pos).pdf(0.9)) / p_x)\n",
    "p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [2v] Given a binary class variable, the default decision threshold of ğœƒ = 0.5,\n",
    "f(x|ğœƒ) = Pos, if P(Positive|x) > 0\\\n",
    "Else negative\n",
    "\n",
    "can be adjusted. Which decision threshold â€“ 0.3, 0.5 or 0.7 â€“ optimizes testing accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming [7v]\n",
    "\n",
    "**Considering the `pd_speech.arff` dataset available at the homework tab:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) [3v]\n",
    "\n",
    "Using sklearn, considering a 10-fold stratified cross validation (random=0), plot the cumulative\n",
    "testing confusion matrices of ğ‘˜NN (uniform weights, ğ‘˜ = 5, Euclidean distance) and NaÃ¯ve Bayes\n",
    "(Gaussian assumption). Use all remaining classifier parameters as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the ARFF file\n",
    "data = loadarff(\"../data/pd_speech.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "df[\"class\"] = df[\"class\"].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from the outcome (class)\n",
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=10, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_knn = KNeighborsClassifier(\n",
    "    weights=\"uniform\", n_neighbors=5, metric=\"euclidean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_naive_bayes = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_prob = []\n",
    "naive_bayes_prob = []\n",
    "\n",
    "knn_acc = []\n",
    "naive_bayes_acc = []\n",
    "\n",
    "y_test_values = []\n",
    "\n",
    "for train_k, test_k in folds.split(X, y):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_k], X.iloc[test_k]\n",
    "    y_train, y_test = y.iloc[train_k], y.iloc[test_k]\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    predictor_knn.fit(X_train, y_train)\n",
    "    predictor_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "    knn_test_pred = predictor_knn.predict(X_test)\n",
    "    naive_bayes_test_pred = predictor_naive_bayes.predict(X_test)\n",
    "\n",
    "    knn_prob += knn_test_pred.tolist()\n",
    "    naive_bayes_prob += naive_bayes_test_pred.tolist()\n",
    "    y_test_values += y_test.tolist()\n",
    "\n",
    "    # Get the accuracy of each test\n",
    "    knn_acc.append(accuracy_score(y_test, knn_test_pred))\n",
    "    naive_bayes_acc.append(accuracy_score(y_test, naive_bayes_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cm = np.array(confusion_matrix(y_test_values, knn_prob, labels=([\"0\", \"1\"])))\n",
    "\n",
    "knn_confusion = pd.DataFrame(\n",
    "    knn_cm,\n",
    "    index=[\"Healthy\", \"Parkinson\"],\n",
    "    columns=[\"Predicted Healthy\", \"Predicted Parkinson\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(knn_confusion, annot=True, fmt=\"g\", cmap=\"Greens\", ax=ax)\n",
    "ax.set_title(\"kNN Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_naive_bayes = np.array(\n",
    "    confusion_matrix(y_test_values, naive_bayes_prob, labels=([\"0\", \"1\"]))\n",
    ")\n",
    "\n",
    "confusion_naive_bayes = pd.DataFrame(\n",
    "    cm_naive_bayes,\n",
    "    index=[\"Healthy\", \"Parkinson\"],\n",
    "    columns=[\"Predicted Healthy\", \"Predicted Parkinson\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "sns.heatmap(confusion_naive_bayes, annot=True, fmt=\"g\", cmap=\"Greens\", ax=ax)\n",
    "ax.set_title(\"Naive Bayes Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) [2v] Using scipy, test the hypothesis â€œğ‘˜NN is statistically superior to NaÃ¯ve Bayes regarding accuracyâ€, asserting whether is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictor 1 is better than 2?\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"less\")\n",
    "print(\"knn > naive_bayes? pval=\", res.pvalue)\n",
    "\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"greater\")\n",
    "print(\"knn < naive_bayes? pval=\", res.pvalue)\n",
    "\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"two-sided\")\n",
    "print(\"knn == naive_bayes? pval=\", res.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusion*: By the p-value gathered (pval = 0.0.9986831821715092) we cannot reject the hypothesis \"kNN is statistically superior to NaÃ¯ve Bayes regarding accuracy\".\n",
    "\n",
    "VERIFICA Q ESTA CENA ESTA BEM PFV\n",
    "\n",
    "\"Examples for use are scores of the same set of student in different exams, or repeated sampling from the same units. The test measures whether the average score differs significantly across samples (e.g. exams). If we observe a large p-value, for example greater than 0.05 or 0.1 then we cannot reject the null hypothesis of identical average scores. If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%, then we reject the null hypothesis of equal averages. Small p-values are associated with large t-statistics.\" COPIADO DA NET retirar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) [2v] Enumerate three possible reasons that could underlie the observed differences in predictive accuracy between ğ‘˜NN and NaÃ¯ve Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enumerate five possible reasons that could underlie the observed differences in predictive accuracy between ğ‘˜NN and NaÃ¯ve Bayes.\n",
    "\n",
    "# 1. The data is not normally distributed\n",
    "# 2. The data is not independent\n",
    "# 3. The data is not homoscedastic\n",
    "# 4. The data is not balanced\n",
    "# 5. The data is not linearly separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN DISAVANTAGES\n",
    "\n",
    "Accuracy depends on the quality of the data\n",
    "Sensitive to the scale of the data, IT SHOULD BE NORMALIZED and irrelevant features\n",
    "\n",
    "\n",
    "NAIVE BAYES DISAVANTAGES\n",
    "\n",
    "It assumes that all the features are independent. While it might sound great in theory, in real life, youâ€™ll hardly find a set of independent features. \n",
    "Highly doubt q todas sejam independentes\n",
    "f your test data set has a categorical variable of a category that wasnâ€™t present in the training data set, the Naive Bayes model will assign it zero probability and wonâ€™t be able to make any predictions in this regard.\n",
    "\n",
    "A third problem arises for continuous features. It is common to use a binning procedure to make them discrete, but if you are not careful you can throw away a lot of information. Another possibility is to use Gaussian distributions for the likelihoods "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}

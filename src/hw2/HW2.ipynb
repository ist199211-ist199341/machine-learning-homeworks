{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework I\n",
    "\n",
    "Diogo Correia (ist199211) & Tom√°s Esteves (ist199341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [13v]\n",
    "\n",
    "**Four positive observations,{$ A \\choose 0 $, $ B \\choose 1 $, $ A \\choose 1 $, $ A \\choose 0 $} , , and four negative observations, {$ B \\choose 0 $, $ B \\choose 0 $, $ A \\choose 1 $, $ B \\choose 1 $} , were collected. Consider the problem of classifying observations as positive or negative.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [4v] Compute the recall of a distance-weighted ùëòNN with ùëò = 5 and distance ùëë(ùê±1 , ùê±2) = ùêªùëéùëöùëöùëñùëõùëî(ùê±1 , ùê±2) + $\\frac{1}{2}$ using leave-one-out evaluation schema (i.e., when classifying one observation, use all remaining ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/hw2data.csv\")\n",
    "\n",
    "df = df.drop(\"y3\", axis=1)\n",
    "df = df.drop(df.index[4])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTANCE_IF_EQUAL = 1 / 2\n",
    "DISTANCE_IF_1_DIFFERENT = 3 / 2\n",
    "DISTANCE_IF_2_DIFFERENT = 5 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <td colspan=\"2\" rowspan=\"2\" style=\"border-top: none; border-left: none;\"></td>\n",
    "    <th colspan=\"2\">True</th>\n",
    "    <td rowspan=\"2\" style=\"border-top: none; border-right: none;\"></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Positive</th>\n",
    "    <th>Negative</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Predicted</th>\n",
    "    <th>Positive</th>\n",
    "    <td>2</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>Negative</th>\n",
    "    <td>2</td>\n",
    "    <td>?</td>\n",
    "    <td>?</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th colspan=\"2\" style=\"border-left: none; border-bottom: none;\"></th>\n",
    "    <td>4</td>\n",
    "    <td>?</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE_POSITIVE = 2\n",
    "FALSE_NEGATIVE = 2\n",
    "\n",
    "recall = TRUE_POSITIVE / (TRUE_POSITIVE + FALSE_NEGATIVE)\n",
    "\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An additional negitive observation was acquired, ( $ùêµ \\choose 0$), and a third variable ùë¶3 was independently monitored, yielding estimates ùë¶3|ùëÉ = {1.2, 0.8, 0.5, 0.9,0.8} , and ùë¶3|ùëÅ = {1, 0.9, 1.2, 0.8}.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [4v] Considering the nine training observations, learn a Bayesian classifier assuming:\n",
    "i) ùë¶1 and ùë¶2 are dependent\\\n",
    "ii) {ùë¶1, ùë¶2} , and {ùë¶3} , variable sets are independent and equally important\\\n",
    "ii) ùë¶3 is normally distributed. \n",
    "\n",
    "Show all parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/hw2data.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Posterior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\n",
    "P( class \\ | \\ y_1 = v_1, \\ y_2 = v_2) = \\frac{P(y_1 = v_1, \\ y_2 = v_2 | \\ class) \\times P(class)}{P(y_1 = v_1, \\ y_2 = v_2)} \n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(pos) = \\frac{5}{9}, \\ \\ \\\n",
    "P(neg) = \\frac{4}{9}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0) = \\frac{2}{9} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1) = \\frac{2}{9} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0) = \\frac{3}{9} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1) = \\frac{2}{9}   \\ \\ \\\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0 \\ | Pos) = \\frac{2}{5} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1 \\ | Pos) = \\frac{1}{5} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0 \\ | Pos) = \\frac{1}{5} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1 \\ | Pos) = \\frac{1}{5}   \\ \\ \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y_1 = A, \\ y_2 = 0 \\ | Neg) = \\frac{0}{4} , \\ \\ \\\n",
    "P(y_1 = A, \\ y_2 = 1 \\ | Neg) = \\frac{1}{4} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 0 \\ | Neg) = \\frac{2}{4} , \\ \\ \\\n",
    "P(y_1 = B, \\ y_2 = 1 \\ | Neg) = \\frac{1}{4}   \\ \\ \\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(x | \\mu, \\sigma^2) = \\mathcal{N}(x | \\mu, \\sigma^2) = \\frac{e ^{- \\frac{(x- \\mu)^2}{2 \\sigma^2}}}{\\sqrt{2 \\pi} \\times \\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(y3) \\          \\mu = 0.9, \\ \\sigma = 0.21794494717703364\\\\\n",
    "P(y3 | \\ Pos) \\  \\mu = 0.8, \\ \\sigma = 0.25099800796022265\\\\\n",
    "P(y3 | \\ Neg) \\  \\mu = 1.0, \\ \\sigma = 0.17078251276599327\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos = 5 / 9\n",
    "prob_neg = 4 / 9\n",
    "\n",
    "prob_A_0 = 2 / 9\n",
    "prob_A_1 = 2 / 9\n",
    "prob_B_0 = 3 / 9\n",
    "prob_B_1 = 2 / 9\n",
    "\n",
    "prob_A_0_pos = 2 / 5\n",
    "prob_A_1_pos = 1 / 5\n",
    "prob_B_0_pos = 1 / 5\n",
    "prob_B_1_pos = 1 / 5\n",
    "\n",
    "prob_A_0_neg = 0\n",
    "prob_A_1_neg = 1 / 4\n",
    "prob_B_0_neg = 2 / 4\n",
    "prob_B_1_neg = 1 / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy\n",
    "\n",
    "y3_values = df[\"y3\"]\n",
    "\n",
    "mean_all = round(numpy.mean(y3_values), 1)\n",
    "sd_all = numpy.std(y3_values, ddof=1)\n",
    "\n",
    "print(\"all\", mean_all, sd_all)\n",
    "\n",
    "y3_values_pos = y3_values[:5]\n",
    "\n",
    "mean_pos = round(numpy.mean(y3_values_pos), 1)\n",
    "sd_pos = numpy.std(y3_values_pos, ddof=1)\n",
    "\n",
    "print(\"positive\", mean_pos, sd_pos)\n",
    "\n",
    "y3_values_neg = y3_values[5:]\n",
    "\n",
    "mean_neg = round(numpy.mean(y3_values_neg), 1)\n",
    "sd_neg = numpy.std(y3_values_neg, ddof=1)\n",
    "\n",
    "print(\"negative\", mean_neg, sd_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_12 = scipy.stats.norm(mean_all, sd_all).cdf(1.2)\n",
    "prob_08 = scipy.stats.norm(mean_all, sd_all).cdf(0.8)\n",
    "prob_05 = scipy.stats.norm(mean_all, sd_all).cdf(0.5)\n",
    "prob_09 = scipy.stats.norm(mean_all, sd_all).cdf(0.9)\n",
    "prob_1 = scipy.stats.norm(mean_all, sd_all).cdf(1)\n",
    "\n",
    "prob_12_pos = scipy.stats.norm(mean_pos, sd_pos).cdf(1.2)\n",
    "prob_08_pos = scipy.stats.norm(mean_pos, sd_pos).cdf(0.8)\n",
    "prob_05_pos = scipy.stats.norm(mean_pos, sd_pos).cdf(0.5)\n",
    "prob_09_pos = scipy.stats.norm(mean_pos, sd_pos).cdf(0.9)\n",
    "prob_1_pos = scipy.stats.norm(mean_pos, sd_pos).cdf(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_pos_A_0_y3 = prob_pos * prob_A_0_pos / (prob_A_0)\n",
    "prob_pos_A_1_y3 = prob_pos * prob_A_1_pos / (prob_A_1)\n",
    "prob_pos_B_0_y3 = prob_pos * prob_B_0_pos / (prob_B_0)\n",
    "prob_pos_B_1_y3 = prob_pos * prob_B_1_pos / (prob_B_1)\n",
    "\n",
    "prob_neg_A_0_y3 = prob_neg * prob_A_0_neg / (prob_A_0)\n",
    "prob_neg_A_1_y3 = prob_neg * prob_A_1_neg / (prob_A_1)\n",
    "prob_neg_B_0_y3 = prob_neg * prob_B_0_neg / (prob_B_0)\n",
    "prob_neg_B_1_y3 = prob_neg * prob_B_1_neg / (prob_B_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Considering three testing observations, {((A, 1, 0.8), Positive), ((B, 1, 1), Positive), ((B, 0, 0.9), Negative)}**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [3v] Under a MAP assumption, compute ùëÉ(Positive|ùê±) of each testing observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos) / P(X)\n",
    "\n",
    "print(prob_pos_A_1_y3 * prob_08_pos / prob_08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(pos|x) = P(x|pos) * p(pos)\n",
    "\n",
    "print(prob_pos_B_1_y3 * prob_1_pos / prob_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prob_pos_B_0_y3 * prob_09_pos / prob_09)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [2v] Given a binary class variable, the default decision threshold of ùúÉ = 0.5,\n",
    "f(x|ùúÉ) = Pos, if P(Positive|x) > 0\\\n",
    "Else negative\n",
    "\n",
    "can be adjusted. Which decision threshold ‚Äì 0.3, 0.5 or 0.7 ‚Äì optimizes testing accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming [7v]\n",
    "\n",
    "**Considering the `pd_speech.arff` dataset available at the homework tab:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) [3v]\n",
    "\n",
    "Using sklearn, considering a 10-fold stratified cross validation (random=0), plot the cumulative\n",
    "testing confusion matrices of ùëòNN (uniform weights, ùëò = 5, Euclidean distance) and Na√Øve Bayes\n",
    "(Gaussian assumption). Use all remaining classifier parameters as default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn import feature_selection, model_selection, tree, metrics, preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the ARFF file\n",
    "data = loadarff(\"../data/pd_speech.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "df[\"class\"] = df[\"class\"].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from the outcome (class)\n",
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = model_selection.StratifiedKFold(n_splits=10, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "predictor_knn = KNeighborsClassifier(\n",
    "    weights=\"uniform\", n_neighbors=5, metric=\"euclidean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "predictor_naive_bayes = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "knn_prob = []\n",
    "test_true = []\n",
    "naive_bayes_prob = []\n",
    "\n",
    "knn_acc = []\n",
    "naive_bayes_acc = []\n",
    "\n",
    "for train_k, test_k in folds.split(X, y):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_k], X.iloc[test_k]\n",
    "    y_train, y_test = y.iloc[train_k], y.iloc[test_k]\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    predictor_knn.fit(X_train, y_train)\n",
    "    predictor_naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "    knn_test_pred = predictor_knn.predict(X_test)\n",
    "    naive_bayes_test_pred = predictor_naive_bayes.predict(X_test)\n",
    "\n",
    "    knn_prob += knn_test_pred.tolist()\n",
    "    test_true += y_test.tolist()\n",
    "    naive_bayes_prob += naive_bayes_test_pred.tolist()\n",
    "\n",
    "    # Get the accuracy of each test\n",
    "    knn_acc.append(metrics.accuracy_score(y_test, knn_test_pred))\n",
    "    naive_bayes_acc.append(metrics.accuracy_score(y_test, naive_bayes_test_pred))\n",
    "\n",
    "print(knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(naive_bayes_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = np.array(confusion_matrix(test_true, knn_prob, labels=([\"0\", \"1\"])))\n",
    "\n",
    "confusion = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Parkinson\", \"Healthy\"],\n",
    "    columns=[\"Predicted Parkinson\", \"Predicted Healthy\"],\n",
    ")\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.array(confusion_matrix(test_true, naive_bayes_prob, labels=([\"0\", \"1\"])))\n",
    "\n",
    "confusion = pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Parkinson\", \"Healthy\"],\n",
    "    columns=[\"Predicted Parkinson\", \"Predicted Healthy\"],\n",
    ")\n",
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) [2v] Using scipy, test the hypothesis ‚ÄúùëòNN is statistically superior to Na√Øve Bayes regarding accuracy‚Äù, asserting whether is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# predictor 1 is better than 2?\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"greater\")\n",
    "print(\"knn > naive_bayes? pval=\", res.pvalue)\n",
    "\n",
    "# predictor 2 is better than 1?\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"less\")\n",
    "print(\"knn < naive_bayes? pval=\", res.pvalue)\n",
    "\n",
    "# performance of predictor 1 differs from predictor 2?\n",
    "res = stats.ttest_rel(knn_acc, naive_bayes_acc, alternative=\"two-sided\")\n",
    "print(\"knn != naive_bayes? pval=\", res.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's true, knn is more accurate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) [2v] Enumerate three possible reasons that could underlie the observed differences in predictive accuracy between ùëòNN and Na√Øve Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}

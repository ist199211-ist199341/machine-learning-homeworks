{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework III\n",
    "\n",
    "Diogo Correia (ist199211) & TomÃ¡s Esteves (ist199341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [12v]\n",
    "\n",
    "**Consider the problem of learning a regression model from 5 univariate observations ((0.8), (1), (1.2), (1.4), (1.6)) with targets (24,20,10,13,12).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"../data/hw3data.csv\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [5v] Consider the basis function, $\\phi_j(x) = x^j$ , for performing a 3-order polynomial regression,\n",
    "\n",
    "$$\n",
    "\\hat{z} (x,w) = \\sum_{j=0}^3 w_j \\phi_j(x) = w_0 + w_1 x + w_2 x^2 + w_3 x^3\n",
    "$$\n",
    "\n",
    "Learn the Ridge regression ($l_2$ regularization) on the transformed data space using the closed form solution with $\\lambda = 2$.\n",
    "\n",
    "Hint: use numpy matrix operations (e.g., linalg.pinv for inverse) to validate your calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "import numpy as np\n",
    "from numpyarray_to_latex import to_ltx\n",
    "from numpyarray_to_latex.jupyter import to_jup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltx(array, **wargs):\n",
    "    print(to_ltx(array, latexarraytype=\"bmatrix\", **wargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df1.drop(\"target\", axis=1)\n",
    "target = np.asmatrix(df1[\"target\"]).transpose()\n",
    "\n",
    "df_x[\"y0\"] = df_x[\"y1\"] ** 0\n",
    "df_x[\"y2\"] = df_x[\"y1\"] ** 2\n",
    "df_x[\"y3\"] = df_x[\"y1\"] ** 3\n",
    "\n",
    "# swap columns\n",
    "y1 = np.asarray(df_x[[\"y0\", \"y1\", \"y2\", \"y3\"]])\n",
    "ltx(y1)\n",
    "to_jup(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_transposed = y1.transpose()\n",
    "ltx(y1_transposed)\n",
    "to_jup(y1_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1t_y1 = np.matmul(y1_transposed, y1)\n",
    "ltx(y1t_y1)\n",
    "to_jup(y1t_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1t_y1_with_lambda = y1t_y1 + 2 * np.identity(4)\n",
    "ltx(\n",
    "    y1t_y1_with_lambda,\n",
    "    mark_color=\"bblue\",\n",
    "    mark_elements=[\n",
    "        (0, 0),\n",
    "        (1, 1),\n",
    "        (2, 2),\n",
    "        (3, 3),\n",
    "    ],\n",
    ")\n",
    "to_jup(y1t_y1_with_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted = np.linalg.inv(y1t_y1_with_lambda)\n",
    "ltx(inverted)\n",
    "to_jup(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_mult = np.matmul(inverted, y1_transposed)\n",
    "ltx(inverted_mult)\n",
    "to_jup(inverted_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.matmul(inverted_mult, target)\n",
    "ltx(w, mark_elements=[(i, 0) for i in range(4)])\n",
    "to_jup(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"W0: \", w[0])\n",
    "print(\"W1: \", w[1])\n",
    "print(\"W2: \", w[2])\n",
    "print(\"W3: \", w[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [1v] Compute the training RMSE for the learnt regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z(x1):\n",
    "    return np.matmul(w.transpose(), np.array([1, x1, x1**2, x1**3]))\n",
    "\n",
    "\n",
    "pred = list(map(z, df_x[\"y1\"]))\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(df_x[\"y1\"][i], target[i], pred[i])\n",
    "    sum += (target[i] - pred[i]) ** 2\n",
    "\n",
    "rmse = np.sqrt(sum / 5)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [6v] Consider a multi-layer perceptron characterized by one hidden layer with 2 nodes. \n",
    "\n",
    "Using the activation function $f(x) = e^{0.1x}$ on all units, all weights initialized as 1 (including biases), and the half squared error loss.\n",
    "\n",
    "Perform one batch gradient descent update (with learning rate $ \\eta = 0.1$) for the first three observations (0.8), (1) and (1.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming and Critical Anlaysis[8v]\n",
    "\n",
    "**Consider the following three regressors applied on kin8nm.arff data (available at the webpage):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- linear regression with Ridge regularization term of 0.1\n",
    "- two MLPs\n",
    "     - ğ‘€ğ¿ğ‘ƒ1 and ğ‘€ğ¿ğ‘ƒ2 \n",
    "- each with two hidden layers of size 10, hyperbolic tangent function as the activation function of all nodes, a maximum of 500 iterations, and a fixed seed (random_state=0). \n",
    "- ğ‘€ğ¿ğ‘ƒ1 should be parameterized with early stopping while ğ‘€ğ¿ğ‘ƒ2 should not consider early stopping. \n",
    "\n",
    "Remaining parameters (e.g., loss function, batch size, regularization term, solver) should be set as default\n",
    "\n",
    "Using a 70-30 training-test split with a fixed seed (random_state=0):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [4v] **Compute the MAE of the three regressors: linear regression, ğ‘€ğ¿ğ‘ƒ1 and ğ‘€ğ¿ğ‘ƒ2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn import feature_selection, model_selection, tree, metrics, preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the ARFF file\n",
    "data = loadarff(\"../data/kin8nm.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from the outcome (class)\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a training set (70%) and a testing set (30%)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X.values, y.values, train_size=0.7, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = MLPRegressor(\n",
    "    hidden_layer_sizes=(10, 10),\n",
    "    activation=\"tanh\",\n",
    "    max_iter=500,\n",
    "    random_state=0,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(10, 10),\n",
    "    activation=\"tanh\",\n",
    "    max_iter=500,\n",
    "    random_state=0,\n",
    "    early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.fit(X_train, y_train)\n",
    "mlp1.fit(X_train, y_train)\n",
    "mlp2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_pred = rr.predict(X_test)\n",
    "mlp1_pred = mlp1.predict(X_test)\n",
    "mlp2_pred = mlp2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge Regularization MAE:\", metrics.mean_absolute_error(y_test, rr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP1 Regularization MAE:\", metrics.mean_absolute_error(y_test, mlp1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP2 Regularization MAE:\", metrics.mean_absolute_error(y_test, mlp2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) [1.5v] **Plot the residues (in absolute value) using two visualizations: boxplots and histograms.**\n",
    "\n",
    "Hint: consider using boxplot and hist functions from matplotlib.pyplot to this end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_residues = []\n",
    "mlp1_residues = []\n",
    "mlp2_residues = []\n",
    "\n",
    "for i in range(0, len(y_test)):\n",
    "    rr_residues.append(abs(y_test[i] - rr_pred[i]))\n",
    "    mlp1_residues.append(abs(y_test[i] - mlp1_pred[i]))\n",
    "    mlp2_residues.append(abs(y_test[i] - mlp2_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Ridge\": rr_residues, \"MLP1\": mlp1_residues, \"MLP2\": mlp2_residues})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) [1v] **How many iterations were required for ğ‘€ğ¿ğ‘ƒ1 and ğ‘€ğ¿ğ‘ƒ2 to converge?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP1 number of iterations:\", mlp1.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP2 number of iterations:\", mlp2.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) [1.5v] **What can be motivating the unexpected differences on the number of iterations?**\n",
    "\n",
    "**Hypothesize one reason underlying the observed performance differences between the MLPs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about the MLP regressor at https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework III\n",
    "\n",
    "Diogo Correia (ist199211) & Tomás Esteves (ist199341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Pen and Paper [12v]\n",
    "\n",
    "**Consider the problem of learning a regression model from 5 univariate observations ((0.8), (1), (1.2), (1.4), (1.6)) with targets (24,20,10,13,12).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"../data/hw3data.csv\")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) [5v] Consider the basis function, $\\phi_j(x) = x^j$ , for performing a 3-order polynomial regression,\n",
    "\n",
    "$$\n",
    "\\hat{z} (x,w) = \\sum_{j=0}^3 w_j \\phi_j(x) = w_0 + w_1 x + w_2 x^2 + w_3 x^3\n",
    "$$\n",
    "\n",
    "Learn the Ridge regression ($l_2$ regularization) on the transformed data space using the closed form solution with $\\lambda = 2$.\n",
    "\n",
    "Hint: use numpy matrix operations (e.g., linalg.pinv for inverse) to validate your calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "import numpy as np\n",
    "from numpyarray_to_latex import to_ltx\n",
    "from numpyarray_to_latex.jupyter import to_jup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ltx(array, **wargs):\n",
    "    print(to_ltx(array, latexarraytype=\"bmatrix\", **wargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df1.drop(\"target\", axis=1)\n",
    "target = np.asmatrix(df1[\"target\"]).transpose()\n",
    "\n",
    "df_x[\"y0\"] = df_x[\"y1\"] ** 0\n",
    "df_x[\"y2\"] = df_x[\"y1\"] ** 2\n",
    "df_x[\"y3\"] = df_x[\"y1\"] ** 3\n",
    "\n",
    "# swap columns\n",
    "y1 = np.asarray(df_x[[\"y0\", \"y1\", \"y2\", \"y3\"]])\n",
    "ltx(y1)\n",
    "to_jup(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_transposed = y1.transpose()\n",
    "ltx(y1_transposed)\n",
    "to_jup(y1_transposed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1t_y1 = np.matmul(y1_transposed, y1)\n",
    "ltx(y1t_y1)\n",
    "to_jup(y1t_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1t_y1_with_lambda = y1t_y1 + 2 * np.identity(4)\n",
    "ltx(\n",
    "    y1t_y1_with_lambda,\n",
    "    mark_color=\"bblue\",\n",
    "    mark_elements=[\n",
    "        (0, 0),\n",
    "        (1, 1),\n",
    "        (2, 2),\n",
    "        (3, 3),\n",
    "    ],\n",
    ")\n",
    "to_jup(y1t_y1_with_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted = np.linalg.inv(y1t_y1_with_lambda)\n",
    "ltx(inverted)\n",
    "to_jup(inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_mult = np.matmul(inverted, y1_transposed)\n",
    "ltx(inverted_mult)\n",
    "to_jup(inverted_mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.matmul(inverted_mult, target)\n",
    "ltx(w, mark_elements=[(i, 0) for i in range(4)])\n",
    "to_jup(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"W0: \", w[0])\n",
    "print(\"W1: \", w[1])\n",
    "print(\"W2: \", w[2])\n",
    "print(\"W3: \", w[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) [1v] Compute the training RMSE for the learnt regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z(x1):\n",
    "    return np.matmul(w.transpose(), np.array([1, x1, x1**2, x1**3]))\n",
    "\n",
    "\n",
    "pred = list(map(z, df_x[\"y1\"]))\n",
    "\n",
    "sum = 0\n",
    "\n",
    "for i in range(0, 5):\n",
    "    print(df_x[\"y1\"][i], target[i], pred[i])\n",
    "    sum += (target[i] - pred[i]) ** 2\n",
    "\n",
    "rmse = np.sqrt(sum / 5)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) [6v] Consider a multi-layer perceptron characterized by one hidden layer with 2 nodes. \n",
    "\n",
    "Using the activation function $f(x) = e^{0.1x}$ on all units, all weights initialized as 1 (including biases), and the half squared error loss.\n",
    "\n",
    "Perform one batch gradient descent update (with learning rate $ \\eta = 0.1$) for the first three observations (0.8), (1) and (1.2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming and Critical Anlaysis[8v]\n",
    "\n",
    "**Consider the following three regressors applied on kin8nm.arff data (available at the webpage):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- linear regression with Ridge regularization term of 0.1\n",
    "- two MLPs\n",
    "     - 𝑀𝐿𝑃1 and 𝑀𝐿𝑃2 \n",
    "- each with two hidden layers of size 10, hyperbolic tangent function as the activation function of all nodes, a maximum of 500 iterations, and a fixed seed (random_state=0). \n",
    "- 𝑀𝐿𝑃1 should be parameterized with early stopping while 𝑀𝐿𝑃2 should not consider early stopping. \n",
    "\n",
    "Remaining parameters (e.g., loss function, batch size, regularization term, solver) should be set as default\n",
    "\n",
    "Using a 70-30 training-test split with a fixed seed (random_state=0):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) [4v] **Compute the MAE of the three regressors: linear regression, 𝑀𝐿𝑃1 and 𝑀𝐿𝑃2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "from sklearn import feature_selection, model_selection, tree, metrics, preprocessing\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the ARFF file\n",
    "data = loadarff(\"../data/kin8nm.arff\")\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features from the outcome (class)\n",
    "X = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into a training set (70%) and a testing set (30%)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X.values, y.values, train_size=0.7, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr = Ridge(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = MLPRegressor(\n",
    "    hidden_layer_sizes=(10, 10),\n",
    "    activation=\"tanh\",\n",
    "    max_iter=500,\n",
    "    random_state=0,\n",
    "    early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPRegressor(\n",
    "    hidden_layer_sizes=(10, 10),\n",
    "    activation=\"tanh\",\n",
    "    max_iter=500,\n",
    "    random_state=0,\n",
    "    early_stopping=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr.fit(X_train, y_train)\n",
    "mlp1.fit(X_train, y_train)\n",
    "mlp2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_pred = rr.predict(X_test)\n",
    "mlp1_pred = mlp1.predict(X_test)\n",
    "mlp2_pred = mlp2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ridge Regularization MAE:\", metrics.mean_absolute_error(y_test, rr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP1 Regularization MAE:\", metrics.mean_absolute_error(y_test, mlp1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP2 Regularization MAE:\", metrics.mean_absolute_error(y_test, mlp2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) [1.5v] **Plot the residues (in absolute value) using two visualizations: boxplots and histograms.**\n",
    "\n",
    "Hint: consider using boxplot and hist functions from matplotlib.pyplot to this end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_residues = []\n",
    "mlp1_residues = []\n",
    "mlp2_residues = []\n",
    "\n",
    "for i in range(0, len(y_test)):\n",
    "    rr_residues.append(abs(y_test[i] - rr_pred[i]))\n",
    "    mlp1_residues.append(abs(y_test[i] - mlp1_pred[i]))\n",
    "    mlp2_residues.append(abs(y_test[i] - mlp2_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Ridge\": rr_residues, \"MLP1\": mlp1_residues, \"MLP2\": mlp2_residues})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=df)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) [1v] **How many iterations were required for 𝑀𝐿𝑃1 and 𝑀𝐿𝑃2 to converge?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP1 number of iterations:\", mlp1.n_iter_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLP2 number of iterations:\", mlp2.n_iter_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) [1.5v] **What can be motivating the unexpected differences on the number of iterations?**\n",
    "\n",
    "**Hypothesize one reason underlying the observed performance differences between the MLPs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about the MLP regressor at https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
